{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heat Tutorial\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original version of this tutorial was inspired by the [CS228 tutorial](https://github.com/kuleshov/cs228-material/blob/master/tutorials/python/cs228-python-tutorial.ipynb) by Volodomyr Kuleshov and Isaac Caswell.\n",
    "\n",
    "For this interactive HPC adaptation, we have heavily referenced the [HPC Python](https://gitlab.jsc.fz-juelich.de/sdlbio-courses/hpc-python) course and the [jupyter-jsc](https://github.com/FZJ-JSC/jupyter-jsc-notebooks) repository. Many thanks Jan Meinke, Jens Henrik Goebbert, Tim Kreuzer, Alice Gorsch @ JSC for help setting this up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "---\n",
    "\n",
    "**Table of Contents**\n",
    "(copilot generated, needs to be updated)\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Getting Started](#Getting-Started)\n",
    "3. [Heat Basics](#Heat-Basics)\n",
    "4. [Heat Arrays](#Heat-Arrays)\n",
    "5. [Heat Operations](#Heat-Operations)\n",
    "\n",
    "\n",
    "<div style=\"float: right; padding-right: 2em; padding-top: 2em;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/helmholtz-analytics/heat/master/doc/images/logo.png\"></img>\n",
    "</div>\n",
    "\n",
    "\n",
    "FILL OUT LATER\n",
    "\n",
    "\n",
    "This tutorial is designed to run on [Jupyter Notebook servers at the  Jülich Supercomputing Centre](https://jupyter-jsc.fz-juelich.de/). \n",
    "\n",
    "deRSE24 participants will have [received instructions](https://pad.gwdg.de/s2GbnPwcTWeSK-OFKs4nAw#) on how to request compute resources associated with the training. \n",
    "\n",
    "HERE INSERT SCREENSHOT OF THE JUPYTER-JSC HUB\n",
    "\n",
    "Log in to the [jupyter-jsc](https://jupyter-jsc.fz-juelich.de/) hub and start a new terminal. In the terminal, copy the tutorial repository:\n",
    "\n",
    "\n",
    "In general, you can install Heat easily via `pip install heat` or `conda install - conda-forge heat`, with the main dependencies being:\n",
    " - some MPI distribution and `mpi4py`;\n",
    " - a `torch` installation suited to your hardware accelerators (if any). \n",
    " \n",
    " Installation on an HPC system is also straightforward, but heavily tuned to the available hardware. In this short tutorial, we will skip the installation part, and use a dedicated kernel that we have created in advance. \n",
    " \n",
    " You do need to load the cluster modules needed for the kernel to work. In the terminal, type:\n",
    "\n",
    "```bash\n",
    "source /p/project/training2404/training2404.sh\n",
    "```\n",
    "THIS NEEDS FIXING\n",
    "\n",
    "Now click on Select Kernel and choose the `heat1.3.1` kernel. \n",
    "\n",
    "Before we can test if Heat can be imported, we need to initialize the `ipcluster`. In the terminal, type:\n",
    "\n",
    "```bash\n",
    "ipcontroller  &\n",
    "srun -n 4 -c 12 --ntasks-per-node 4 --time 00:30:00   -A training2404 ipengine start\n",
    "```\n",
    "On your terminal, you should see something like this:\n",
    "\n",
    "```bash\n",
    "FILL OUT\n",
    "```\n",
    "\n",
    "Reload the kernel. You now have access to 4 MPI processes that can be used by Heat either on CPU, or on the 4 GPUs available on each node.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics: what is Heat for?\n",
    "---\n",
    "\n",
    "Straight from our [GitHub repository](https://github.com/helmholtz-analytics/heat):\n",
    "\n",
    "Heat builds on [PyTorch](https://pytorch.org/) and [mpi4py](https://mpi4py.readthedocs.io) to provide high-performance computing infrastructure for memory-intensive applications within the NumPy/SciPy ecosystem.\n",
    "\n",
    "\n",
    "With Heat you can:\n",
    "- port existing NumPy/SciPy code from single-CPU to multi-node clusters with minimal coding effort;\n",
    "- exploit the entire, cumulative RAM of your many nodes for memory-intensive operations and algorithms;\n",
    "- run your NumPy/SciPy code on GPUs (CUDA, ROCm, coming up: Apple MPS).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In practice\n",
    "\n",
    "FILL IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heat Arrays\n",
    "---\n",
    "\n",
    "To be able to start working with Heat on an HPC cluster, we first need to check the health of the available processes. We will use the `ipyparallel` client for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipyparallel import Client\n",
    "rc = Client(profile=\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have started the `ipcontroller` and `ipengine` processes with 4 processes. We can now check if the processes are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc.ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Here explain %%px magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stderr:3] /p/scratch/training2404/jupyter/kernels/heat1.3.1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
       "  from .autonotebook import tqdm as notebook_tqdm\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stderr:2] /p/scratch/training2404/jupyter/kernels/heat1.3.1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
       "  from .autonotebook import tqdm as notebook_tqdm\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stderr:0] /p/scratch/training2404/jupyter/kernels/heat1.3.1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
       "  from .autonotebook import tqdm as notebook_tqdm\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stderr:1] /p/scratch/training2404/jupyter/kernels/heat1.3.1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
       "  from .autonotebook import tqdm as notebook_tqdm\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px: 100%|██████████| 4/4 [00:07<00:00,  1.96s/tasks]\n"
     ]
    }
   ],
   "source": [
    "%px import heat as ht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to a NumPy array, a Heat array is a grid of values of a single (one particular) type. The number of dimensions is the number of axes of the array, while the shape of an array is a tuple of integers giving the number of elements of the array along each dimension. \n",
    "\n",
    "Heat emulates NumPy's API as closely as possible, allowing for the use of well-known array creation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, because we are running these cells of a 4-process \"cluster\", each print statement will be printed 4 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[stdout:0] tensor([], device='cuda:3', dtype=torch.int64)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] tensor([2], device='cuda:1')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:3] tensor([1], device='cuda:0')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:1] tensor([3], device='cuda:2')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "import heat as ht\n",
    "a = ht.array([1, 2, 3])\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNDarray([[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]], dtype=ht.float32, device=cpu:0, split=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px\n",
    "ht.ones((4, 5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNDarray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=ht.int32, device=cpu:0, split=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px\n",
    "ht.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNDarray([[9., 9.],\n",
       "          [9., 9.],\n",
       "          [9., 9.]], dtype=ht.float32, device=cpu:0, split=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px\n",
    "ht.full((3, 2,), fill_value=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types\n",
    "\n",
    "Heat supports various data types and operations to retrieve and manipulate the type of a Heat array. However, in contrast to NumPy, Heat is limited to logical (bool) and numerical types (uint8, int16/32/64, float32/64, and complex64/128). \n",
    "\n",
    "**NOTE:** by default, Heat will allocate floating-point values in single precision, due to a much higher processing performance on GPUs. This is one of the main differences between Heat and NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DNDarray([[0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0.]], dtype=ht.float32, device=cpu:0, split=None),\n",
       " heat.core.types.float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px\n",
    "a = ht.zeros((3, 4,))\n",
    "a, a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DNDarray([[0, 0, 0, 0],\n",
       "           [0, 0, 0, 0],\n",
       "           [0, 0, 0, 0]], dtype=ht.int64, device=cpu:0, split=None),\n",
       " heat.core.types.int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px\n",
    "b = a.astype(ht.int64)\n",
    "b, b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNDarray([[0, 0, 0, 0],\n",
       "          [0, 0, 0, 0],\n",
       "          [0, 0, 0, 0]], dtype=ht.int8, device=cpu:0, split=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px\n",
    "ht.zeros((3, 4,), dtype=ht.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations\n",
    "\n",
    "Heat supports several mathematical operations, ranging from simple element-wise functions, binary arithmetic operations, and linear algebra, to more powerful reductions. Operations are by default performed on the entire array or they can be performed along one or more of its dimensions when available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "a = ht.full((3, 4,), 8)\n",
    "b = ht.ones((3, 4,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNDarray([[9., 9., 9., 9.],\n",
       "          [9., 9., 9., 9.],\n",
       "          [9., 9., 9., 9.]], dtype=ht.float32, device=cpu:0, split=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNDarray([[7., 7., 7., 7.],\n",
       "          [7., 7., 7., 7.],\n",
       "          [7., 7., 7., 7.]], dtype=ht.float32, device=cpu:0, split=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px\n",
    "ht.sub(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNDarray([ 0.0000,  0.8415,  0.9093,  0.1411, -0.7568], dtype=ht.float32, device=cpu:0, split=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px\n",
    "ht.arange(5).sin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNDarray([[8., 8., 8.],\n",
       "          [8., 8., 8.],\n",
       "          [8., 8., 8.],\n",
       "          [8., 8., 8.]], dtype=ht.float32, device=cpu:0, split=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px\n",
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNDarray([4., 4., 4.], dtype=ht.float32, device=cpu:0, split=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px\n",
    "b.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Heat implements the same broadcasting rules (implicit repetion of an operation when the rank/shape of the operands do not match) as NumPy does, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNDarray([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=ht.int64, device=cpu:0, split=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px\n",
    "ht.arange(10) + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DNDarray([[1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.]], dtype=ht.float32, device=cpu:0, split=None),\n",
       " DNDarray([0, 1, 2, 3], dtype=ht.int32, device=cpu:0, split=None),\n",
       " DNDarray([[1., 2., 3., 4.],\n",
       "           [1., 2., 3., 4.],\n",
       "           [1., 2., 3., 4.]], dtype=ht.float32, device=cpu:0, split=None))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px\n",
    "a = ht.ones((3, 4,))\n",
    "b = ht.arange(4)\n",
    "c = a + b\n",
    "\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "Heat allows the indexing of arrays, and thereby, the extraction of a partial view of the elements in an array. It is possible to obtain single values as well as entire chunks, i.e. slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNDarray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=ht.int32, device=cpu:0, split=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px\n",
    "a = ht.arange(10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNDarray(3, dtype=ht.int32, device=cpu:0, split=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px\n",
    "a[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNDarray([1, 2, 3, 4, 5, 6], dtype=ht.int32, device=cpu:0, split=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px\n",
    "a[1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNDarray([0, 2, 4, 6, 8], dtype=ht.int32, device=cpu:0, split=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px\n",
    "a[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Indexing in Heat is undergoing a major overhaul, to increase interoperability with NumPy/PyTorch indexing, and to provide a fully distributed item setting functionality. If you're interested, you can preview the new indexing functionality by loading the `heat-dev-indexing` kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation\n",
    "\n",
    "Heat is extensively documented. You may find the online API reference on Read the Docs: [Heat Documentation](https://heat.readthedocs.io/). It is also possible to look up the docs in an interactive session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sum in module heat.core.arithmetics:\n",
      "\n",
      "sum(a: 'DNDarray', axis: 'Union[int, Tuple[int, ...]]' = None, out: 'DNDarray' = None, keepdim: 'bool' = None) -> 'DNDarray'\n",
      "    Sum of array elements over a given axis. An array with the same shape as ``self.__array`` except for the specified\n",
      "    axis which becomes one, e.g. ``a.shape=(1, 2, 3)`` => ``ht.ones((1, 2, 3)).sum(axis=1).shape=(1, 1, 3)``\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : DNDarray\n",
      "        Input array.\n",
      "    axis : None or int or Tuple[int,...], optional\n",
      "        Axis along which a sum is performed. The default, ``axis=None``, will sum all of the elements of the input array.\n",
      "        If ``axis`` is negative it counts from the last to the first axis. If ``axis`` is a tuple of ints, a sum is performed\n",
      "        on all of the axes specified in the tuple instead of a single axis or all the axes as before.\n",
      "    out : DNDarray, optional\n",
      "        Alternative output array in which to place the result. It must have the same shape as the expected output, but\n",
      "        the datatype of the output values will be cast if necessary.\n",
      "    keepdim : bool, optional\n",
      "        If this is set to ``True``, the axes which are reduced are left in the result as dimensions with size one. With this\n",
      "        option, the result will broadcast correctly against the input array.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> ht.sum(ht.ones(2))\n",
      "    DNDarray([2.], dtype=ht.float32, device=cpu:0, split=None)\n",
      "    >>> ht.sum(ht.ones((3,3)))\n",
      "    DNDarray([9.], dtype=ht.float32, device=cpu:0, split=None)\n",
      "    >>> ht.sum(ht.ones((3,3)).astype(ht.int))\n",
      "    DNDarray([9], dtype=ht.int64, device=cpu:0, split=None)\n",
      "    >>> ht.sum(ht.ones((3,2,1)), axis=-3)\n",
      "    DNDarray([[3.],\n",
      "             [3.]], dtype=ht.float32, device=cpu:0, split=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "help(ht.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Processing\n",
    "---\n",
    "\n",
    "Heat's actual power lies in the possibility to exploit the processing performance of modern accelerator hardware (GPUs) as well as distributed (high-performance) cluster systems. All operations executed on CPUs are, to a large extent, vectorized (AVX) and thread-parallelized (OpenMP). Heat builds on PyTorch, so it supports GPU acceleration on Nvidia and AMD GPUs. \n",
    "\n",
    "For distributed computations, your system or laptop needs to have Message Passing Interface (MPI) installed. For GPU computations, your system needs to have one or more suitable GPUs and (MPI-aware) CUDA/ROCm ecosystem.\n",
    "\n",
    "**NOTE:** The GPU examples below will only properly execute on a computer with a CUDA GPU. Make sure to either start the notebook on an appropriate machine or copy and paste the examples into a script and execute it on a suitable device.\n",
    "\n",
    "**NOTE: ** All examples below explaining the distributed processing capabilities need to be executed outside this notebook in a separate MPI-capable environment. We suggest to copy and paste the code snippets into a script and execute it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPUs\n",
    "\n",
    "Heat's array creation functions all support an additional parameter that which places the data on a specific device. By default, the CPU is selected, but it is also possible to directly allocate the data on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNDarray([[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]], dtype=ht.float32, device=gpu:0, split=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.zeros((3, 4,), device='gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays on the same device can be seamlessly used in any Heat operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNDarray([[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]], dtype=ht.float32, device=gpu:0, split=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ht.zeros((3, 4,), device='gpu')\n",
    "b = ht.ones((3, 4,), device='gpu')\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, performing operations on arrays with mismatching devices will purposefully result in an error (due to potentially large copy overhead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "a = ht.full((3, 4,), 4, device='cpu')\n",
    "b = ht.ones((3, 4,), device='gpu')\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to explicitly move an array from one device to the other and back to avoid this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNDarray([[4., 4., 4., 4.],\n",
       "          [4., 4., 4., 4.],\n",
       "          [4., 4., 4., 4.]], dtype=ht.float32, device=cpu:0, split=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ht.full((3, 4,), 4, device='gpu')\n",
    "a.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When writing code for GPUs only, you might quickly find it tedious to explicitly place everything on the GPU by specifying the `device=` parameter. Hence, it is possible to set a default backend on which Heat will work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht.use_device('gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Computing\n",
    "\n",
    "Heat is also able to make use of distributed processing capabilities such as those in high-performance cluster systems. For this, Heat exploits the fact that the operations performed on a multi-dimensional array are usually identical for all data items. Hence, a data-parallel processing strategy can be chosen, where the total number of data items is equally divided among all processing nodes. An operation is then performed individually on the local data chunks and, if necessary, communicates partial results behind the scenes. A Heat array assumes the role of a virtual overlay of the local chunks and realizes and coordinates the computations. Please see the figure below for a visual representation of this concept.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/helmholtz-analytics/heat/master/doc/images/heat_split_array.png\" width=\"40%\"></img>\n",
    "\n",
    "The chunks are always split along a singular dimension (i.e. 1D domain decomposition) of the array. You can specify this in Heat by using the `split` paramter. This parameter is present in all relevant functions, such as array creation (`zeros(), ones(), ...`) or I/O (`load()`) functions. Examples are provided below. The result of an operation on a Heat tensor will in most cases preserve the split of the respective operands. However, in some cases the split axis might change. For example, a transpose of a Heat array will equally transpose the split axis. Furthermore, a reduction operations, e.g. `sum()` that is performed across the split axis, might remove data partitions entirely. The respective function behaviors can be found in Heat's documentation.\n",
    "\n",
    "You may also modify the data partitioning of a Heat array by using the `resplit()` function. This allows you to repartition the data as you so choose. Please note, that this should be used sparingly and for small data amounts only, as it entails significant data copying across the network. Finally, a Heat array without any split, i.e. `split=None` (default), will result in redundant copies of data on each computation node.\n",
    "\n",
    "On a technical level, Heat follows the so-called [Bulk Synchronous Parallel (BSP)](https://en.wikipedia.org/wiki/Bulk_synchronous_parallel) processing model. For the network communication, Heat utilizes the [Message Passing Interface (MPI)](https://computing.llnl.gov/tutorials/mpi/), a defacto standard on modern high-performance computing systems. It is also possible to use MPI on your laptop or desktop computer. Respective software packages are available for all major operating systems. In order to run a Heat script, you need to start it slightly differently than you are probably used to. This\n",
    "\n",
    "```bash\n",
    "python ./my_script.py\n",
    "```\n",
    "\n",
    "becomes this instead:\n",
    "\n",
    "```bash\n",
    "mpirun -p <number_of_processors> python ./my_script.py\n",
    "```\n",
    "\n",
    "Let's see some examples of working with distributed Heat\n",
    "\n",
    "**NOTE: ** In the following we will use a `(<processor_id>/<processor_count>)` prefix on each output to clearly show, what each individual process is printing. In actual application you would not observe this behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Unsplit\" data, i.e. local copies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0/2) tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32)\n",
       "(1/2) tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.arange(10, split=None)  # equivalent to just saying ht.arange(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data division along the major axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0/2) tensor([0, 1, 2, 3, 4], dtype=torch.int32)\n",
       "(1/2) tensor([5, 6, 7, 8, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.arange(10, split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other split axes are also possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0/2) tensor([[1, 2],\n",
       "(0/2)         [5, 6]]),\n",
       "(1/2) tensor([[3, 4],\n",
       "(1/2)         [7, 8]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.array([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8]\n",
    "], split=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repartitioning of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0/2) tensor([[0., 0., 0.],\n",
       "(0/2)         [0., 0., 0.],\n",
       "(0/2)         [0., 0., 0.],\n",
       "(0/2)         [0., 0., 0.]])\n",
       "(1/2) tensor([[0., 0., 0.],\n",
       "(1/2)         [0., 0., 0.],\n",
       "(1/2)         [0., 0., 0.],\n",
       "(1/2)         [0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ht.zeros((4, 6,), split=1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0/2) tensor([[0., 0., 0., 0., 0., 0.],\n",
       "(0/2)         [0., 0., 0., 0., 0., 0.]])\n",
       "(1/2) tensor([[0., 0., 0., 0., 0., 0.],\n",
       "(1/2)         [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.resplit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0/2) tensor([3, 4, 5, 6, 7], dtype=torch.int32)\n",
       "(1/2) tensor([8, 9, 10, 11, 12], dtype=torch.int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.arange(10, split=0) + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations between tensors with equal split or no split are fully parallelizable and therefore very fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0/2) tensor([1, 2, 3, 4, 5], dtype=torch.int32)\n",
       "(1/2) tensor([6, 7, 8, 9, 10], dtype=torch.int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ht.arange(10, split=0)\n",
    "b = ht.ones((10,), split=0)\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Interactive Interpreter\n",
    "\n",
    "Heat allows you to interactively program and debug distributed code. The root process will spawn an interactive shell, that forwards the inputs to all other ranks and equally collects the output of all nodes. The interactive interpreter can be found in the Heat sources in the path `scripts/interactive.py` or can be download like this `wget https://raw.githubusercontent.com/helmholtz-analytics/heat/master/scripts/interactive.py`.\n",
    "\n",
    "You can start the interactive interpreter by invoking the following command. The `-s all` flag must be passed to the interpeter for it to work.\n",
    "\n",
    "```bash\n",
    "mpirun -s all -np <procs> python interactive.py\n",
    "```\n",
    "\n",
    "**NOTE: ** the interactive interpreter unfortunately does not support the full set of control commands, disallowing 'arrow-up' command repetition for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dos and Don'ts\n",
    "\n",
    "In this section we would like to address a few best practices for programming with Heat. While we can obviously not cover all issues, these are major pointers as how to get reasonable performance.\n",
    "\n",
    "**Dos**\n",
    "\n",
    "* Split up large data amounts\n",
    "    * often you input data set along the 'observations/samples' dimension\n",
    "    * large intermediate matrices\n",
    "* Use the Heat API\n",
    "    * computational kernels are optimized\n",
    "    * Python constructs (e.g. loops) tend to be slow\n",
    "* Potentially have a copy of certain data with different splits\n",
    "\n",
    "**Dont's**\n",
    "\n",
    "* Avoid extensive data copying, e.g.\n",
    "    * operations with operands of different splits (except None)\n",
    "    * reshape() that actually change the array dimensions (adding extra dimensions with size 1 is fine)\n",
    "* Execute everything on GPU\n",
    "    * computation-intensive operations are usually a good fit\n",
    "    * operations extensively accessing memory only (e.g. sorting) are not"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heat1.3.1",
   "language": "python",
   "name": "heat1.3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
