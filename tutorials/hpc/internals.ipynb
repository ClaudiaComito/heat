{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heat as infrastructure for MPI applications\n",
    "\n",
    "In this section, we'll go through some Heat-specific functionalities that simplify the implementation a data-parallel application in Python. We'll demonstrate them on small arrays and 4 processes on a single cluster node, but the functionalities are identical in a multi-node set up with huge arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we start with the necessary imports and setting up the cluster. On the terminal window, start the `ipcontroller` and `ipengine` processes.\n",
    "    \n",
    "```bash\n",
    "ipcontroller &\n",
    "srun -n 4 -c 12 --ntasks-per-node 4 --time 00:30:00   -A training2404 -p dc_gpu ipengine start\n",
    "```\n",
    "\n",
    "Reload the kernel. We should now again have 4 MPI processes available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyparallel import Client\n",
    "rc = Client(profile=\"default\")\n",
    "rc.ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already mentioned that the DNDarray object is \"MPI-aware\". Each DNDarray is associated to an MPI communicator, it is aware of the number of processes in the communicator, and it knows the rank of the process that owns it. \n",
    "\n",
    "We will use the %%px magic in every cell that executes MPI code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "a = ht.random.randn(7,4,3, split=0)\n",
    "a.comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# MPI size = total number of processes \n",
    "size = a.comm.size\n",
    "\n",
    "print(f\"a is distributed over {size} processes\")\n",
    "print(f\"a is a distributed {a.ndim}-dimensional array with global shape {a.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# MPI rank = rank of each process\n",
    "rank = a.comm.rank\n",
    "# Local shape = shape of the data on each process\n",
    "local_shape = a.lshape\n",
    "print(f\"Rank {rank} holds a slice of a with local shape {local_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many occasions it will be useful for each rank to have information on how the array is distributed across all processes. The `lshape_map` attribute of a DNDarray gathers this info from all processes amd stores it as metadata of the DNDarray. Because it is meant for internal use, it is stored in a torch tensor, not a DNDarray. \n",
    "\n",
    "The `lshape_map` tensor is a 2D tensor, where the first dimension is the number of processes and the second dimension is the number of dimensions of the array. Each row of the tensor contains the local shape of the array on a process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "lshape_map = a.lshape_map\n",
    "lshape_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can go back to the previous cell and create `a` with a different split axis. See how the `lshape_map` changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redistribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the is_split attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts and displs"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
